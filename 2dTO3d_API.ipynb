{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beatriz-sait07/Computacao-grafica/blob/main/2dTO3d_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrWb9J3dvWe9"
      },
      "source": [
        "# Retornando uma matriz q talvez seja um arquivo .obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXgrH-PevVsk",
        "outputId": "8f01f42e-864f-4634-fe3c-116f283d55dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pifuhd'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (126/126), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 222 (delta 92), reused 82 (delta 82), pack-reused 96 (from 1)\u001b[K\n",
            "Receiving objects: 100% (222/222), 399.39 KiB | 19.02 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "Cloning into 'lightweight-human-pose-estimation.pytorch'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 124 (delta 21), reused 19 (delta 18), pack-reused 90 (from 1)\u001b[K\n",
            "Receiving objects: 100% (124/124), 230.29 KiB | 10.97 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "/content/lightweight-human-pose-estimation.pytorch\n",
            "--2025-02-15 20:02:39--  https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\n",
            "Resolving download.01.org (download.01.org)... 23.203.77.88, 2600:1413:a000:118a::a87, 2600:1413:a000:1182::a87\n",
            "Connecting to download.01.org (download.01.org)|23.203.77.88|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87959810 (84M) [application/octet-stream]\n",
            "Saving to: ‘checkpoint_iter_370000.pth’\n",
            "\n",
            "checkpoint_iter_370 100%[===================>]  83.88M   219MB/s    in 0.4s    \n",
            "\n",
            "2025-02-15 20:02:42 (219 MB/s) - ‘checkpoint_iter_370000.pth’ saved [87959810/87959810]\n",
            "\n",
            "/content/pifuhd\n",
            "+ mkdir -p checkpoints\n",
            "+ cd checkpoints\n",
            "+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n",
            "--2025-02-15 20:02:42--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.254.15, 108.157.254.102, 108.157.254.121, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.254.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548375177 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘pifuhd.pt’\n",
            "\n",
            "pifuhd.pt           100%[===================>]   1.44G   254MB/s    in 11s     \n",
            "\n",
            "2025-02-15 20:02:53 (131 MB/s) - ‘pifuhd.pt’ saved [1548375177/1548375177]\n",
            "\n",
            "--2025-02-15 20:02:53--  http://pifuhd.pt/\n",
            "Resolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘pifuhd.pt’\n",
            "FINISHED --2025-02-15 20:02:53--\n",
            "Total wall clock time: 11s\n",
            "Downloaded: 1 files, 1.4G in 11s (131 MB/s)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0+cu124) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0+cu124) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.0+cu124) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0+cu124) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0+cu124) (3.0.2)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu124\n",
            "    Uninstalling torchaudio-2.5.1+cu124:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.0+cu124 torchaudio-2.5.0+cu124 torchvision-0.20.0+cu124\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok, flask-cors\n",
            "Successfully installed flask-cors-5.0.0 pyngrok-7.2.3\n"
          ]
        }
      ],
      "source": [
        "# Clonar repositório PIFuHD e Lightweight-Human-Pose-Estimation\n",
        "!git clone https://github.com/facebookresearch/pifuhd\n",
        "!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git\n",
        "\n",
        "# Baixar checkpoint para pose estimation\n",
        "%cd /content/lightweight-human-pose-estimation.pytorch/\n",
        "!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\n",
        "\n",
        "# Baixar modelos pré-treinados do PIFuHD\n",
        "%cd /content/pifuhd/\n",
        "!sh ./scripts/download_trained_model.sh\n",
        "\n",
        "# Instalar versão específica do PyTorch (se necessário) e demais pacotes\n",
        "!pip install torch==2.5.0+cu124 torchvision==0.20.0+cu124 torchaudio==2.5.0+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install flask flask-cors pyngrok\n",
        "\n",
        "# Ajustar arquivo que usa np.bool (desatualizado)\n",
        "!sed -i 's/np.bool/bool/g' /content/pifuhd/lib/sdf.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_el-mZs9vlbQ",
        "outputId": "a0530129-5ceb-44aa-a006-9602bd67cab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lightweight-human-pose-estimation.pytorch\n",
            "Collecting rembg\n",
            "  Downloading rembg-2.0.62-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from rembg) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rembg) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from rembg) (4.11.0.86)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from rembg) (1.8.2)\n",
            "Collecting pymatting (from rembg)\n",
            "  Downloading PyMatting-1.1.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from rembg) (0.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from rembg) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from rembg) (4.67.1)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->rembg) (0.22.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->rembg) (2.32.3)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.11/dist-packages (from pymatting->rembg) (0.61.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (2025.1.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->rembg) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.44.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->rembg) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->rembg) (2025.1.31)\n",
            "Downloading rembg-2.0.62-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyMatting-1.1.13-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, pymatting, coloredlogs, onnxruntime, rembg\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.1 pymatting-1.1.13 rembg-2.0.62\n",
            "/content/pifuhd\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Flask\n",
        "from flask import Flask, request, send_file, jsonify\n",
        "from flask_cors import CORS\n",
        "\n",
        "# Pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Pose Estimation imports\n",
        "%cd /content/lightweight-human-pose-estimation.pytorch/\n",
        "import demo\n",
        "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
        "from modules.load_state import load_state\n",
        "from modules.keypoints import extract_keypoints, group_keypoints\n",
        "from modules.pose import Pose\n",
        "\n",
        "# Remover fundo\n",
        "!pip install rembg pillow onnxruntime\n",
        "from rembg import remove\n",
        "from PIL import Image\n",
        "\n",
        "def load_pose_model(pose_model_path='checkpoint_iter_370000.pth'):\n",
        "    net = PoseEstimationWithMobileNet()\n",
        "    checkpoint = torch.load(pose_model_path, map_location='cpu')\n",
        "    load_state(net, checkpoint)\n",
        "    net = net.cuda().eval()\n",
        "    return net\n",
        "\n",
        "def get_rect(net, image_path, height_size=512):\n",
        "    \"\"\"\n",
        "    Gera o arquivo _rect.txt necessário para o PIFuHD quando usamos --use_rect.\n",
        "    \"\"\"\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "\n",
        "    rect_path = image_path.replace('.%s' % (image_path.split('.')[-1]), '_rect.txt')\n",
        "\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "    all_keypoints_by_type = []\n",
        "    total_keypoints_num = 0\n",
        "    for kpt_idx in range(num_keypoints):\n",
        "        total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "    pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "    for kpt_id in range(all_keypoints.shape[0]):\n",
        "        all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "        all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "\n",
        "    rects = []\n",
        "    for n in range(len(pose_entries)):\n",
        "        if len(pose_entries[n]) == 0:\n",
        "            continue\n",
        "        pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "        valid_keypoints = []\n",
        "        for kpt_id in range(num_keypoints):\n",
        "            if pose_entries[n][kpt_id] != -1.0:\n",
        "                pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "        valid_keypoints = np.array(valid_keypoints)\n",
        "\n",
        "        if len(valid_keypoints) == 0:\n",
        "            continue\n",
        "\n",
        "        if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "            pmin = valid_keypoints.min(0)\n",
        "            pmax = valid_keypoints.max(0)\n",
        "            center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.float32)\n",
        "            radius = int(0.65 * max(pmax[0] - pmin[0], pmax[1] - pmin[1]))\n",
        "        elif (pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and\n",
        "              pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0):\n",
        "            center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.float32)\n",
        "            radius = int(1.45 * np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "            center[1] += int(0.05 * radius)\n",
        "        else:\n",
        "            center = np.array([img.shape[1] // 2, img.shape[0] // 2], dtype=np.float32)\n",
        "            radius = max(img.shape[1] // 2, img.shape[0] // 2)\n",
        "\n",
        "        x1 = int(center[0] - radius)\n",
        "        y1 = int(center[1] - radius)\n",
        "        rects.append([x1, y1, 2 * radius, 2 * radius])\n",
        "\n",
        "    np.savetxt(rect_path, np.array(rects), fmt='%d')\n",
        "    return rect_path\n",
        "\n",
        "# Agora voltamos pro /content/pifuhd pois a pasta apps/simple_test.py está lá\n",
        "%cd /content/pifuhd/\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def run_pifuhd(net, image_path, resolution=256):\n",
        "    \"\"\"\n",
        "    1) Gera o arquivo _rect.txt (com get_rect)\n",
        "    2) Roda o apps.simple_test\n",
        "    3) Retorna o caminho do .obj\n",
        "    \"\"\"\n",
        "    # Gera .txt\n",
        "    get_rect(net, image_path)\n",
        "\n",
        "    folder = os.path.dirname(image_path)\n",
        "    filename_no_ext = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    obj_path = f'/content/pifuhd/results/pifuhd_final/recon/result_{filename_no_ext}_{resolution}.obj'\n",
        "\n",
        "    cmd = [\n",
        "      \"python\", \"-m\", \"apps.simple_test\",\n",
        "      \"-r\", str(resolution),\n",
        "      \"--use_rect\",\n",
        "      \"-i\", folder\n",
        "    ]\n",
        "    # Importante: rodar com cwd=/content/pifuhd pra encontrar o pacote apps\n",
        "    subprocess.run(cmd, check=True, cwd=\"/content/pifuhd\")\n",
        "\n",
        "    return obj_path\n",
        "\n",
        "def remove_background(input_path, output_path):\n",
        "    \"\"\"\n",
        "    Remove o fundo da imagem antes de processá-la no PIFuHD.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(input_path)\n",
        "        img_no_bg = remove(img)\n",
        "        img_no_bg.save(output_path)\n",
        "        return output_path\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao remover fundo: {e}\")\n",
        "        return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP1rilaFvpTz",
        "outputId": "675b2d94-4dd6-4666-b8cb-efc962de187f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-35e50aee515d>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(pose_model_path, map_location='cpu')\n"
          ]
        }
      ],
      "source": [
        "# 1) Carrega modelo de pose (uma única vez)\n",
        "pose_net = load_pose_model('/content/lightweight-human-pose-estimation.pytorch/checkpoint_iter_370000.pth')\n",
        "\n",
        "# 2) Define a aplicação Flask\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/pifuhd', methods=['POST'])\n",
        "def pifuhd_endpoint():\n",
        "    \"\"\"\n",
        "    Requisição:\n",
        "      curl -X POST -F \"image=@/caminho/imagem.png\" <URL>/pifuhd -o resultado.obj\n",
        "    \"\"\"\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({\"error\": \"Nenhuma imagem recebida. Utilize multipart form field name='image'.\"}), 400\n",
        "\n",
        "    # Salva a imagem em /content/pifuhd/sample_images\n",
        "    # filename = \"upload.png\"  # se preferir, pode gerar nomes únicos\n",
        "    # image_path = f'/content/pifuhd/sample_images/{filename}'\n",
        "\n",
        "    # image_file = request.files['image']\n",
        "    # image_file.save(image_path)\n",
        "\n",
        "     # Caminhos dos arquivos\n",
        "    original_filename = \"upload.png\"\n",
        "    processed_filename = \"upload_no_bg.png\"\n",
        "    original_path = f'/content/pifuhd/sample_images/{original_filename}'\n",
        "    processed_path = f'/content/pifuhd/sample_images/{processed_filename}'\n",
        "\n",
        "    # Salva a imagem original\n",
        "    image_file = request.files['image']\n",
        "    image_file.save(original_path)\n",
        "\n",
        "    # Remove o fundo da imagem\n",
        "    processed_path = remove_background(original_path, processed_path)\n",
        "    if processed_path is None:\n",
        "        return jsonify({\"error\": \"Falha ao remover fundo da imagem.\"}), 500\n",
        "\n",
        "    # Executa o PIFuHD\n",
        "    try:\n",
        "        obj_path = run_pifuhd(pose_net, processed_path, resolution=256)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        return jsonify({\"error\": f\"Falha ao rodar PIFuHD: {str(e)}\"}), 500\n",
        "\n",
        "    # Retorna o arquivo .obj\n",
        "    return send_file(obj_path, as_attachment=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQAZss6bNWBa",
        "outputId": "fb97fe38-bfd3-4dc1-9331-9ab543d3fcf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL pública: https://5fa4-34-142-194-196.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-02-15T20:06:35+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-bd83ec9d-c8ab-49b1-bc05-13ed71efe0c0 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ],
      "source": [
        "# 3) ngrok - configure seu token\n",
        "NGROK_AUTH_TOKEN = \"2sm6vyo1h04eE0HtlJZOpzk7ixT_7Vb4Z3sUE3E6ipB4kn1yB\"  # pegue em https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Before connecting, check if a tunnel is already running\n",
        "active_tunnels = ngrok.get_tunnels()\n",
        "if len(active_tunnels) > 0:\n",
        "    # Reuse the existing tunnel\n",
        "    public_url = active_tunnels[0].public_url\n",
        "    print(\"Reusing existing tunnel:\", public_url)\n",
        "else:\n",
        "    # Start a new tunnel\n",
        "    tunnel = ngrok.connect(5000) # Store the tunnel object\n",
        "    public_url = tunnel.public_url # Get the public URL from the tunnel object\n",
        "    print(\"URL pública:\", public_url)\n",
        "\n",
        "# ... (rest of your code) ...\n",
        "\n",
        "# After your app has finished running, close the tunnel\n",
        "ngrok.disconnect(public_url) # Disconnect using the public URL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pegue a ***URL publica*** abaixo para conexão com o front"
      ],
      "metadata": {
        "id": "UuVs1pe9OHYy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T0uGTFsvsNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a679f6a6-c64c-4bc4-fe47-692570afa6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL pública: https://e054-34-142-194-196.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Feb/2025 20:09:25] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n",
            "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n",
            "100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 139GB/s]\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Feb/2025 20:12:14] \"POST /pifuhd HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Feb/2025 20:13:50] \"\u001b[35m\u001b[1mPOST /pifuhd HTTP/1.1\u001b[0m\" 500 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Feb/2025 20:14:27] \"\u001b[35m\u001b[1mPOST /pifuhd HTTP/1.1\u001b[0m\" 500 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Feb/2025 20:16:40] \"POST /pifuhd HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Feb/2025 20:17:18] \"POST /pifuhd HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "public_url = ngrok.connect(5000).public_url\n",
        "print(\"URL pública:\", public_url)\n",
        "\n",
        "# 4) Iniciar flask\n",
        "app.run(host=\"0.0.0.0\", port=5000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}